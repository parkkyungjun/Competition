{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import sys\n!pip install -q sktime\nimport sktime\nimport tqdm as tq\nimport xgboost as xgb\nimport matplotlib\nimport seaborn as sns\nimport sklearn as skl\nimport pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom sktime.forecasting.model_selection import temporal_train_test_split\nfrom sktime.utils.plotting import plot_series\nfrom xgboost import XGBRegressor\n\npd.set_option('display.max_columns', 30)\n\n\ndef weighted_mse(alpha = 1):\n    def weighted_mse_fixed(label, pred):\n        residual = (label - pred).astype(\"float\")\n        grad = np.where(residual>0, -2*alpha*residual, -2*residual)\n        hess = np.where(residual>0, 2*alpha, 2.0)\n        return grad, hess\n    return weighted_mse_fixed\n\ndef SMAPE(true, pred):\n    v = 2 * abs(pred - true) / (abs(pred) + abs(true))\n    output = np.mean(v) * 100\n    return output","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-07-29T16:11:56.217861Z","iopub.execute_input":"2023-07-29T16:11:56.218261Z","iopub.status.idle":"2023-07-29T16:12:17.036706Z","shell.execute_reply.started":"2023-07-29T16:11:56.218228Z","shell.execute_reply":"2023-07-29T16:12:17.035507Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"def get_train2():\n    info = pd.read_csv('/kaggle/input/big-one/building_info.csv').drop(['태양광용량(kW)','ESS저장용량(kWh)', 'PCS용량(kW)'], axis=1)\n    info.columns = ['building', 'type', 'all_area', 'cool_area']\n    types = info['type'].unique()\n    value_dict = {value: index for index, value in enumerate(types)}\n    info['type'] = info['type'].map(value_dict)\n\n    info.loc[64, 'cool_area'] = 146585.0\n    info.loc[65, 'cool_area'] = 83781.0\n    info.loc[67, 'cool_area'] = 310488.0\n    info.loc[76, 'cool_area'] = 35716.0\n    info.loc[79, 'cool_area'] = 135899.6\n\n    np.random.seed(0)\n\n    cols = ['num_date_time', 'building', 'date_time', 'temp', 'prec','wind', 'hum', 'target']\n\n    train = pd.read_csv('/kaggle/input/big-one/train.csv').drop(['일조(hr)', '일사(MJ/m2)'], axis=1)\n\n    train['풍속(m/s)'] = train['풍속(m/s)'].fillna(method='ffill')\n    train['습도(%)'] = train['습도(%)'].fillna(method='ffill')\n    train = train.fillna(0)\n    train.columns = cols\n    train = train.merge(info, on='building', how='left')\n\n    test = pd.read_csv('/kaggle/input/big-one/test.csv')\n    test.columns = cols[:-1]\n    test = test.merge(info, on='building', how='left')\n\n    def add_data(df):\n        for i in range(2):\n            np.random.seed(i)\n            num_rows = len(df)\n\n            random_temp = df['temp'] * np.random.uniform(0.9, 1.1, num_rows)\n            random_prec = df['prec'] * np.random.uniform(0.9, 1.1, num_rows)\n            random_wind = df['wind'] * np.random.uniform(0.9, 1.1, num_rows)\n            random_hum = df['hum'] * np.random.uniform(0.9, 1.1, num_rows)\n\n            # 소수 첫째 자리까지 반올림\n            random_temp = np.round(random_temp, 1)\n            random_prec = np.round(random_prec, 1)\n            random_wind = np.round(random_wind, 1)\n            random_hum = np.round(random_hum, 1)\n\n            # 새로운 데이터프레임 생성\n\n            new_df = df.copy()\n            new_df['temp'] = random_temp\n            new_df['prec'] = random_prec\n            new_df['wind'] = random_wind\n            new_df['hum'] = random_hum\n\n            # 기존 데이터프레임과 새로운 데이터프레임을 이어붙임\n            df = pd.concat([df, new_df], ignore_index=True)\n        df = df.sort_values(by=['building', 'date_time']).reset_index(drop=True)\n        return df\n\n\n    # 시간 관련 변수들 생성\n    date = pd.to_datetime(train.date_time)\n    train['hour'] = date.dt.hour\n    train['dow'] = date.dt.weekday\n    train['month'] = date.dt.month\n    train['week'] = date.dt.isocalendar().week\n    train['day'] = date.dt.day\n\n    avg_temp = pd.pivot_table(train[train['hour']%3 == 0], values = 'temp', index = ['building', 'day'], aggfunc = np.mean).reset_index()\n    avg_temp.rename(columns={'temp': 'avg_temp'}, inplace=True)\n    train = pd.merge(train, avg_temp, on=['building', 'day'], how='left')\n\n    date = pd.to_datetime(test.date_time)\n    test['hour'] = date.dt.hour\n    test['dow'] = date.dt.weekday\n    test['month'] = date.dt.month\n    test['week'] = date.dt.isocalendar().week\n    test['day'] = date.dt.day\n\n    avg_temp = pd.pivot_table(test[test['hour']%3 == 0], values = 'temp', index = ['building', 'day'], aggfunc = np.mean).reset_index()\n    avg_temp.rename(columns={'temp': 'avg_temp'}, inplace=True)\n    test = pd.merge(test, avg_temp, on=['building', 'day'], how='left')\n\n    power_mean = pd.pivot_table(train, values = 'target', index = ['building', 'hour', 'dow'], aggfunc = np.mean).reset_index()\n    power_mean.rename(columns={'target': 'dow_hour_mean'}, inplace=True)\n    train = pd.merge(train, power_mean, on=['building', 'hour', 'dow'], how='left')\n    test = pd.merge(test, power_mean, on=['building', 'hour', 'dow'], how='left')\n\n#     power_std = pd.pivot_table(train, values = 'target', index = ['building', 'hour', 'dow'], aggfunc = np.std).reset_index()\n#     power_std.rename(columns={'target': 'dow_hour_std'}, inplace=True)\n#     train = pd.merge(train, power_std, on=['building', 'hour', 'dow'], how='left')\n#     test = pd.merge(test, power_std, on=['building', 'hour', 'dow'], how='left')\n\n    # type_mean = pd.pivot_table(train, values = 'target', index = ['type', 'hour', 'dow'], aggfunc = np.mean).reset_index()\n    # type_mean.rename(columns={'target': 'type_hour_mean'}, inplace=True)\n    # train = pd.merge(train, type_mean, on=['type', 'hour', 'dow'], how='left')\n    # test = pd.merge(test, type_mean, on=['type', 'hour', 'dow'], how='left')\n\n    # type_std = pd.pivot_table(train, values = 'target', index = ['type', 'hour', 'dow'], aggfunc = np.std).reset_index()\n    # type_std.rename(columns={'target': 'type_hour_std'}, inplace=True)\n    # train = pd.merge(train, type_std, on=['type', 'hour', 'dow'], how='left')\n    # test = pd.merge(test, type_std, on=['type', 'hour', 'dow'], how='left')\n\n    ### 공휴일 변수 추가\n    test['date'] = pd.to_datetime(test['date_time'], format='%Y-%m-%d %H')\n    train['date'] = pd.to_datetime(train['date_time'], format='%Y-%m-%d %H')\n\n    train['holiday'] = train.apply(lambda x : 0 if x['dow'] < 5 else 1, axis = 1)\n    test['holiday'] = test.apply(lambda x : 0 if x['dow'] < 5 else 1, axis = 1)\n\n    train.loc[train['building'] == 3, 'holiday'] = 0\n    train.loc[(train['building'] == 3) & (train['dow'] == 0) , 'holiday'] = 1\n    train.loc[(train['building'] == 3) & (train['date_time'].str.match(r'^20220731 \\d{2}$')) , 'holiday'] = 1\n    train.loc[(train['building'] == 3) & (train['date_time'].str.match(r'^20220723 \\d{2}$')) , 'holiday'] = 1\n    train.loc[(train['building'] == 3) & (train['date_time'].str.match(r'^20220720 \\d{2}$')) , 'holiday'] = 1\n    test.loc[test['building'] == 3, 'holiday'] = 0\n    test.loc[(test['building'] == 3) & (test['dow'] == 0) , 'holiday'] = 1\n\n    train.loc[train['building'] == 2, 'holiday'] = 0\n    train.loc[(train['building'] == 2) & (train['dow'] == 0) , 'holiday'] = 1\n    train.loc[(train['building'] == 2) & (train['date_time'].str.match(r'^20220607 \\d{2}$')) , 'holiday'] = 1\n    train.loc[(train['building'] == 2) & (train['date_time'].str.match(r'^20220617 \\d{2}$')) , 'holiday'] = 1\n    test.loc[test['building'] == 2, 'holiday'] = 0\n    test.loc[(test['building'] == 2) & (test['dow'] == 0) , 'holiday'] = 1\n\n    train.loc[train['building'] == 54, 'holiday'] = 0\n    train.loc[(train['building'] == 54) & (train['dow'] == 0) , 'holiday'] = 1\n    train.loc[(train['building'] == 54) & (train['date_time'].str.match(r'^20220816 \\d{2}$')) , 'holiday'] = 1\n    train.loc[(train['building'] == 54) & (train['date_time'].str.match(r'^20220817 \\d{2}$')) , 'holiday'] = 1\n    test.loc[test['building'] == 54, 'holiday'] = 0\n    test.loc[(test['building'] == 54) & (test['dow'] == 0) , 'holiday'] = 1\n\n    train.loc[(train['date_time'].str.match(r'^20220601 \\d{2}$')) & (train['building'] != 14) , 'holiday'] = 1\n    train.loc[(train['date_time'].str.match(r'^20220606 \\d{2}$')) & (train['building'] != 14), 'holiday'] = 1\n    train.loc[(train['date_time'].str.match(r'^20220815 \\d{2}$')) & (train['building'] != 14), 'holiday'] = 1\n    train.loc[(train['building'] == 14) & (train['date_time'].str.match(r'^20220614 \\d{2}$')) , 'holiday'] = 1\n\n    def week_of_month(date):\n        first_day = date.replace(day=1)\n        if (date.week - first_day.week + 1) % 2 == 0:\n            if date.weekday() == 6:\n                return 1\n        return 0\n\n    train['week_of_month'] = train['date'].apply(week_of_month)\n    test['week_of_month'] = test['date'].apply(week_of_month)\n\n    target_buildings = [87,88,89,90,91,92]\n    train.loc[(train['building'].isin(target_buildings)) , 'holiday'] = 0\n    train.loc[(train['building'].isin(target_buildings)) & (train['week_of_month'] == 1), 'holiday'] = 1\n    test.loc[(test['building'].isin(target_buildings)) , 'holiday'] = 0\n    test.loc[(test['building'].isin(target_buildings)) & (test['week_of_month'] == 1), 'holiday'] = 1\n\n    train.loc[train['building'] == 85, 'holiday'] = 0\n    test.loc[test['building'] == 85, 'holiday'] = 0\n\n    test['date'] = pd.to_datetime(test['date_time'], format='%Y-%m-%d %H').dt.date\n    train['date'] = pd.to_datetime(train['date_time'], format='%Y-%m-%d %H').dt.date\n\n    target_day = ['2022-06-10', '2022-08-10', '2022-07-10', '2022-07-24', '2022-06-26', '2022-07-30']\n    train.loc[train['building'] == 86, 'holiday'] = 0\n    test.loc[test['building'] == 86, 'holiday'] = 0\n    for i in target_day:\n        k = pd.to_datetime(i)\n        train.loc[(train['date'] == k.date()) & (train['building'] == 86), 'holiday'] = 1\n        test.loc[(test['date'] == k.date()) & (train['building'] == 86), 'holiday'] = 1\n\n    power_holiday_mean = pd.pivot_table(train, values = 'target', index = ['building', 'hour', 'holiday'], aggfunc = np.mean).reset_index()\n    power_holiday_mean.rename(columns={'target': 'holiday_mean'}, inplace=True)\n    train = pd.merge(train, power_holiday_mean, on=['building', 'hour', 'holiday'], how='left')\n    test = pd.merge(test, power_holiday_mean, on=['building', 'hour', 'holiday'], how='left')\n\n    power_holiday_std = pd.pivot_table(train, values = 'target', index = ['building', 'hour', 'holiday'], aggfunc = np.std).reset_index()\n    power_holiday_std.rename(columns={'target': 'holiday_std'}, inplace=True)\n    train = pd.merge(train, power_holiday_std, on=['building', 'hour', 'holiday'], how='left')\n    test = pd.merge(test, power_holiday_std, on=['building', 'hour', 'holiday'], how='left')\n\n    power_hour_mean = pd.pivot_table(train, values = 'target', index = ['building', 'hour',], aggfunc = np.mean).reset_index()\n    power_hour_mean.rename(columns={'target': 'hour_mean'}, inplace=True)\n    train = pd.merge(train, power_hour_mean, on=['building', 'hour', ], how='left')\n    test = pd.merge(test, power_hour_mean, on=['building', 'hour', ], how='left')\n\n    power_hour_std = pd.pivot_table(train, values = 'target', index = ['building', 'hour',], aggfunc = np.std).reset_index()\n    power_hour_std.rename(columns={'target': 'hour_std'}, inplace=True)\n    train = pd.merge(train, power_hour_std, on=['building', 'hour', ], how='left')\n    test = pd.merge(test, power_hour_std, on=['building', 'hour', ], how='left')\n\n    # train = add_data(train)\n    # valid = add_data(valid)\n\n    ## https://dacon.io/competitions/official/235680/codeshare/2366?page=1&dtype=recent\n    train['sin_time'] = np.sin(2*np.pi*train.hour/24)\n    train['cos_time'] = np.cos(2*np.pi*train.hour/24)\n    test['sin_time'] = np.sin(2*np.pi*test.hour/24)\n    test['cos_time'] = np.cos(2*np.pi*test.hour/24)\n\n    train['THI'] = 9/5*train['temp'] - 0.55*(1-train['hum']/100)*(9/5*train['hum']-26)+32\n    #train['THI']=pd.cut(train.THI, bins=[-100, 68, 75, 80, 200], labels=['0', '1', '2', '3'])\n    test['THI'] = 9/5*test['temp'] - 0.55*(1-test['hum']/100)*(9/5*test['hum']-26)+32\n    #test['THI']=pd.cut(test.THI, bins=[-100, 68, 75, 80, 200], labels=['0', '1', '2', '3'])\n\n    train['WC']=13.12+0.6215*train['temp']-13.947*train['wind']**0.16+0.486*train['temp']*train['wind']**0.16\n    #train['WC']=pd.cut(train.WC, bins=[-100, 21, 25, 28, 31, 100], labels=[0,1,2,3,4])\n    test['WC']=13.12+0.6215*test['temp']-13.947*test['wind']**0.16+0.486*test['temp']*test['wind']**0.16\n    #test['WC']=pd.cut(test.WC, bins=[-100, 21, 25, 28, 31, 100], labels=[0,1,2,3,4])\n\n    def CDH(xs):\n        ys = []\n        for i in range(len(xs)):\n            if i < 11:\n                ys.append(np.sum(xs[:(i+1)]-26))\n            else:\n                ys.append(np.sum(xs[(i-11):(i+1)]-26))\n        return np.array(ys)\n\n    cdhs = np.array([])\n    for num in range(1,101):\n        temp = train[train['building'] == num]\n        cdh = CDH(temp['temp'].values)\n        cdhs = np.concatenate([cdhs, cdh])\n    train['CDH'] = cdhs\n\n    cdhs = np.array([])\n    for num in range(1,101):\n        temp = test[test['building'] == num]\n        cdh = CDH(temp['temp'].values)\n        cdhs = np.concatenate([cdhs, cdh])\n    test['CDH'] = cdhs\n\n#     train['THI'] = train['THI'].astype('int')\n#     train['WC'] = train['WC'].astype('int')\n#     test['THI'] = test['THI'].astype('int')\n#     test['WC'] = test['WC'].astype('int')\n    train['week'] = train['week'].astype(np.int32)\n    test['week'] = test['week'].astype(np.int32)\n\n    def new_type(i):\n        if i in [1,2,3,8,9,11,12,13,14,15]: return 0\n        elif i in [17,18,19,20,21,22,23]: return 1\n        elif i in [24,25,26,27,28,29,30,31]: return 2\n        elif i in [32,33,34,35,36]: return 3\n        elif i in [37,38,39,40,41,42,43,44]: return 4\n        elif i in [45,46,47,48,49,50,51,52]: return 5\n        elif i in [55,56,57,58]: return 6\n        elif i in [53,54,59,60]: return 7\n        elif i in [61,62,63,64,65,66,67,68]: return 8\n        elif i in [69,70,71,72,73,74,75,76]: return 9\n        elif i in [77,78,79,80,81,82,83,84]: return 10\n        elif i in [87,88,89,90,91,92]: return 11\n        elif i in [93,95,97,98,99,100]: return 12\n        else: return 13\n\n    train['new_type'] = train['building'].apply(new_type)\n    test['new_type'] = test['building'].apply(new_type)\n\n    # 37 : 620 711 88 617\n    # 38 : 613 725 81\n    # 39 : 718 88\n    # 40 : 718 620 617 88\n    # 41 : 627 725 88\n    # 42 : 613 822 711\n    \n    target_buildings = [37,38,39,40,41,42]\n    train.loc[(train['building'].isin(target_buildings)) , 'holiday'] = 0\n    test.loc[(test['building'].isin(target_buildings)) , 'holiday'] = 0\n    train.loc[(train['building'] == 37) & (train['date'].isin([pd.to_datetime(i).date() for i in ['2022-06-20', '2022-07-11', '2022-08-08', '2022-06-17']])), 'holiday'] = 1\n    train.loc[(train['building'] == 38) & (train['date'].isin([pd.to_datetime(i).date() for i in ['2022-06-13', '2022-07-25', '2022-08-01']])), 'holiday'] = 1\n    train.loc[(train['building'] == 39) & (train['date'].isin([pd.to_datetime(i).date() for i in ['2022-07-18', '2022-08-08']])), 'holiday'] = 1\n    train.loc[(train['building'] == 40) & (train['date'].isin([pd.to_datetime(i).date() for i in ['2022-06-20', '2022-07-18', '2022-06-17', '2022-08-08']])), 'holiday'] = 1\n    train.loc[(train['building'] == 41) & (train['date'].isin([pd.to_datetime(i).date() for i in ['2022-06-27', '2022-07-25', '2022-08-08']])), 'holiday'] = 1\n    train.loc[(train['building'] == 42) & (train['date'].isin([pd.to_datetime(i).date() for i in ['2022-06-13', '2022-07-11', '2022-08-22']])), 'holiday'] = 1\n    \n#     train.drop(train[(train['building'] == 37) & (train['date'].isin([pd.to_datetime(i).date() for i in ['2022-06-20', '2022-07-11', '2022-08-08', '2022-06-17']]))].index, inplace=True)\n#     train.drop(train[(train['building'] == 38) & (train['date'].isin([pd.to_datetime(i).date() for i in ['2022-06-13', '2022-07-25', '2022-08-01',]]))].index, inplace=True)\n#     train.drop(train[(train['building'] == 39) & (train['date'].isin([pd.to_datetime(i).date() for i in ['2022-07-18', '2022-08-08',]]))].index, inplace=True)\n#     train.drop(train[(train['building'] == 40) & (train['date'].isin([pd.to_datetime(i).date() for i in ['2022-06-20', '2022-07-18', '2022-06-17', '2022-08-08']]))].index, inplace=True)\n#     train.drop(train[(train['building'] == 41) & (train['date'].isin([pd.to_datetime(i).date() for i in ['2022-06-27', '2022-07-25', '2022-08-08']]))].index, inplace=True)\n#     train.drop(train[(train['building'] == 42) & (train['date'].isin([pd.to_datetime(i).date() for i in ['2022-06-13', '2022-07-11', '2022-08-22',]]))].index, inplace=True)\n\n    train.drop(['hour', 'date', 'week_of_month', 'avg_temp', 'prec', 'type', 'new_type', 'cool_area', 'all_area', 'day'], axis = 1, inplace = True)\n    test.drop(['hour', 'date', 'week_of_month', 'avg_temp', 'prec', 'type', 'new_type', 'cool_area', 'all_area', 'day'], axis = 1, inplace = True)\n\n    print('done')\n    return train, test\ntrain, test = get_train2()","metadata":{"execution":{"iopub.status.busy":"2023-07-29T16:15:24.402479Z","iopub.execute_input":"2023-07-29T16:15:24.402887Z","iopub.status.idle":"2023-07-29T16:15:39.078331Z","shell.execute_reply.started":"2023-07-29T16:15:24.402855Z","shell.execute_reply":"2023-07-29T16:15:39.076980Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"done\n","output_type":"stream"}]},{"cell_type":"code","source":"import optuna\nimport optuna.logging\noptuna.logging.set_verbosity(optuna.logging.WARNING)\n\ndf = pd.DataFrame()\n# \nfor i in tqdm(range(100)):\n    def objective(trial):\n        y = train.loc[train.building == i+1, 'target']\n        x = train.loc[train.building == i+1, ].iloc[:, 3:].drop(['target', ], axis=1)\n        y_train, y_test, x_train, x_test = temporal_train_test_split(y = y, X = x, test_size = 168)\n\n        param = {\n            # 'tree_method':'gpu_hist',  # Use GPU acceleration\n            'reg_lambda': trial.suggest_float('reg_lambda', 1e-3, 10.0),\n            'gamma': trial.suggest_float('gamma', 0, 10),\n            'reg_alpha': trial.suggest_float('reg_alpha', 1e-3, 10.0),\n            'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.5,0.6,0.7,0.8,0.9,1.0]),\n            'subsample': trial.suggest_categorical('subsample', [0.6,0.7,0.8,1.0]),\n            'max_depth': trial.suggest_categorical('max_depth', [3,4,5,6]),\n            'min_child_weight': trial.suggest_int('min_child_weight', 1, 300),\n#            'objective': trial.suggest_categorical('objective', ['reg:squarederror', 'weighted_mse100', 'weighted_mse7'])\n        }\n#         if param['objective'] == 'weighted_mse100':\n#             model = XGBRegressor(n_estimators=100, learning_rate=0.1,\n#                                 reg_lambda=param['reg_lambda'], gamma=param['gamma'],\n#                                 reg_alpha=param['reg_alpha'],\n#                                 colsample_bytree=param['colsample_bytree'], subsample=param['subsample'],\n#                                 max_depth=param['max_depth'], min_child_weight=param['min_child_weight'],\n#                                 objective=weighted_mse(100))\n#         elif param['objective'] == 'weighted_mse7':\n#             model = XGBRegressor(n_estimators=100, learning_rate=0.1,\n#                                 reg_lambda=param['reg_lambda'], gamma=param['gamma'],\n#                                 reg_alpha=param['reg_alpha'],\n#                                 colsample_bytree=param['colsample_bytree'], subsample=param['subsample'],\n#                                 max_depth=param['max_depth'], min_child_weight=param['min_child_weight'],\n#                                 objective=weighted_mse(7))\n#        else:\n        model = XGBRegressor(**param, n_estimators=100, learning_rate=0.1)  \n\n        model.fit(x_train,y_train, verbose=False)\n        preds = model.predict(x_test)\n        \n        return SMAPE(y_test, preds)\n\n\n    study = optuna.create_study(direction='minimize', study_name=None)\n    study.optimize(objective, n_trials=100)\n    df = pd.concat([df, study.trials_dataframe().sort_values(by=['value'], ascending=[True]).head(1)], ignore_index=True)\n\ndf.to_csv('parameters.csv', index=False)\ndf","metadata":{"execution":{"iopub.status.busy":"2023-07-29T17:32:06.878567Z","iopub.execute_input":"2023-07-29T17:32:06.878989Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":" 69%|██████▉   | 69/100 [22:55<11:05, 21.47s/it]","output_type":"stream"}]},{"cell_type":"code","source":"scores = []   # smape 값을 저장할 list\nbest_it = []  # best interation을 저장할 list\nfor i in tqdm(range(1,101)):\n    y = train.loc[train.building == i, 'target']\n    x = train.loc[train.building == i, ].iloc[:, 3:].drop(['target'], axis=1)\n    y_train, y_valid, x_train, x_valid = temporal_train_test_split(y = y, X = x, test_size = 168)\n    \n    xgb_reg = XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n             colsample_bynode=1, colsample_bytree=0.8, eta=0.01, gamma=0,\n             gpu_id=-1, importance_type='gain', interaction_constraints='',\n             learning_rate=0.00999999978, max_delta_step=0, max_depth=5,\n             min_child_weight=6, monotone_constraints='()',\n             n_estimators=10000, n_jobs=0, num_parallel_tree=1, random_state=0,\n             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=0,\n             subsample=0.9, tree_method='exact', validate_parameters=1,\n             verbosity=None, early_stopping_rounds=300)\n    \n    xgb_reg.set_params(**{'objective':weighted_mse(100)})\n    \n    xgb_reg.fit(x_train, y_train, eval_set=[(x_train, y_train), \n                                            (x_valid, y_valid)], verbose=False)\n    \n    y_pred = xgb_reg.predict(x_valid)\n    pred = pd.Series(y_pred)   \n    \n    sm = SMAPE(y_valid, y_pred)\n    scores.append(sm)\n    best_it.append(xgb_reg.best_iteration+1) ## 실제 best iteration은 이 값에 +1 해주어야 함.\nprint(sum(scores)/len(scores))","metadata":{"execution":{"iopub.status.busy":"2023-07-29T16:15:49.677889Z","iopub.execute_input":"2023-07-29T16:15:49.678295Z","iopub.status.idle":"2023-07-29T16:22:43.631458Z","shell.execute_reply.started":"2023-07-29T16:15:49.678264Z","shell.execute_reply":"2023-07-29T16:22:43.630496Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"100%|██████████| 100/100 [06:53<00:00,  4.14s/it]","output_type":"stream"},{"name":"stdout","text":"4.472399041330698\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"alpha_list = []\nsmape_list = []\nxgb_params = pd.DataFrame()\nfor i in tqdm(range(100)):\n    y = train.loc[train.building == i+1, 'target']\n    x = train.loc[train.building == i+1, ].iloc[:, 3:].drop(['target'], axis=1)\n    y_train, y_test, x_train, x_test = temporal_train_test_split(y = y, X = x, test_size = 168)\n    \n    xgb = XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n         colsample_bynode=1, colsample_bytree=0.8, eta=0.01, gamma=0,\n         gpu_id=-1, importance_type='gain', interaction_constraints='',\n         learning_rate=0.00999999978, max_delta_step=0, max_depth=5,\n         min_child_weight=6, monotone_constraints='()',\n         n_estimators=best_it[i], n_jobs=0, num_parallel_tree=1,\n         random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n         seed=0, subsample=0.9, tree_method='exact', validate_parameters=1,\n         verbosity=None,)\n\n    xgb.fit(x_train, y_train)\n    pred0 = xgb.predict(x_test)\n    best_alpha = 0\n    score0 = SMAPE(y_test,pred0)\n    \n    for j in [1, 3, 5, 7, 10, 25, 50, 75, 100]:\n        xgb = XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n                 colsample_bynode=1, colsample_bytree=0.8, eta=0.01, gamma=0,\n                 gpu_id=-1, importance_type='gain', interaction_constraints='',\n                 learning_rate=0.00999999978, max_delta_step=0, max_depth=5,\n                 min_child_weight=6, monotone_constraints='()',\n                 n_estimators=10000, n_jobs=0, num_parallel_tree=1,\n                 random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n                 seed=0, subsample=0.9, tree_method='exact', validate_parameters=1,\n                 verbosity=None, early_stopping_rounds=300)\n\n        xgb.set_params(**{'objective':weighted_mse(j)}) \n\n        xgb.fit(x_train, y_train, eval_set=[(x_train, y_train), \n                                                (x_valid, y_valid)], verbose=False)\n        pred1 = xgb.predict(x_test)\n        score1 = SMAPE(y_test, pred1)\n        if score1 < score0:\n            best_alpha = j\n            score0 = score1\n    \n    alpha_list.append(best_alpha)\n    smape_list.append(score0)\n    print(f\"building {i+1} || best score : {score0} || alpha : {best_alpha}\")\n    \nxgb_params['alpha'] = alpha_list\nxgb_params['best_it'] = best_it\n\nxgb_params.head()","metadata":{"execution":{"iopub.status.busy":"2023-07-29T16:22:43.799292Z","iopub.execute_input":"2023-07-29T16:22:43.799617Z","iopub.status.idle":"2023-07-29T17:01:40.947694Z","shell.execute_reply.started":"2023-07-29T16:22:43.799590Z","shell.execute_reply":"2023-07-29T17:01:40.946900Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"  1%|          | 1/100 [00:17<29:11, 17.69s/it]","output_type":"stream"},{"name":"stdout","text":"building 1 || best score : 5.9840476933026 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":"  2%|▏         | 2/100 [00:39<33:11, 20.32s/it]","output_type":"stream"},{"name":"stdout","text":"building 2 || best score : 9.083105379428497 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":"  3%|▎         | 3/100 [01:03<35:17, 21.83s/it]","output_type":"stream"},{"name":"stdout","text":"building 3 || best score : 9.122044576576444 || alpha : 100\n","output_type":"stream"},{"name":"stderr","text":"  4%|▍         | 4/100 [01:27<36:26, 22.78s/it]","output_type":"stream"},{"name":"stdout","text":"building 4 || best score : 3.7220643337688957 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":"  5%|▌         | 5/100 [01:44<32:40, 20.64s/it]","output_type":"stream"},{"name":"stdout","text":"building 5 || best score : 7.509715010100307 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":"  6%|▌         | 6/100 [02:06<33:12, 21.20s/it]","output_type":"stream"},{"name":"stdout","text":"building 6 || best score : 4.381266565360323 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":"  7%|▋         | 7/100 [02:49<43:36, 28.13s/it]","output_type":"stream"},{"name":"stdout","text":"building 7 || best score : 7.835432425881558 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":"  8%|▊         | 8/100 [03:10<39:33, 25.80s/it]","output_type":"stream"},{"name":"stdout","text":"building 8 || best score : 5.304831799178455 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":"  9%|▉         | 9/100 [03:28<35:37, 23.49s/it]","output_type":"stream"},{"name":"stdout","text":"building 9 || best score : 3.0972792987717184 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 10%|█         | 10/100 [03:43<31:29, 20.99s/it]","output_type":"stream"},{"name":"stdout","text":"building 10 || best score : 6.371807495510394 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 11%|█         | 11/100 [04:00<29:11, 19.68s/it]","output_type":"stream"},{"name":"stdout","text":"building 11 || best score : 3.5368969276988786 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 12%|█▏        | 12/100 [04:23<30:15, 20.63s/it]","output_type":"stream"},{"name":"stdout","text":"building 12 || best score : 3.8550215524763862 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 13%|█▎        | 13/100 [04:39<28:08, 19.41s/it]","output_type":"stream"},{"name":"stdout","text":"building 13 || best score : 6.219704822545139 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 14%|█▍        | 14/100 [04:59<27:49, 19.41s/it]","output_type":"stream"},{"name":"stdout","text":"building 14 || best score : 16.04208755900228 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 15%|█▌        | 15/100 [05:18<27:27, 19.39s/it]","output_type":"stream"},{"name":"stdout","text":"building 15 || best score : 3.4164574725437 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 16%|█▌        | 16/100 [05:36<26:38, 19.04s/it]","output_type":"stream"},{"name":"stdout","text":"building 16 || best score : 4.160002837275592 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 17%|█▋        | 17/100 [06:53<50:06, 36.22s/it]","output_type":"stream"},{"name":"stdout","text":"building 17 || best score : 5.647393893262314 || alpha : 1\n","output_type":"stream"},{"name":"stderr","text":" 18%|█▊        | 18/100 [07:15<43:54, 32.13s/it]","output_type":"stream"},{"name":"stdout","text":"building 18 || best score : 6.800335942141665 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 19%|█▉        | 19/100 [07:43<41:35, 30.81s/it]","output_type":"stream"},{"name":"stdout","text":"building 19 || best score : 7.872283263374749 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 20/100 [08:07<38:15, 28.70s/it]","output_type":"stream"},{"name":"stdout","text":"building 20 || best score : 3.929901706952447 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 21%|██        | 21/100 [08:26<33:54, 25.76s/it]","output_type":"stream"},{"name":"stdout","text":"building 21 || best score : 7.176220684198705 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 22%|██▏       | 22/100 [08:49<32:31, 25.02s/it]","output_type":"stream"},{"name":"stdout","text":"building 22 || best score : 3.6525337497466532 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 23%|██▎       | 23/100 [09:09<30:06, 23.46s/it]","output_type":"stream"},{"name":"stdout","text":"building 23 || best score : 1.4582964458237857 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 24%|██▍       | 24/100 [09:24<26:40, 21.06s/it]","output_type":"stream"},{"name":"stdout","text":"building 24 || best score : 2.3711824437520552 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 25%|██▌       | 25/100 [09:39<23:59, 19.19s/it]","output_type":"stream"},{"name":"stdout","text":"building 25 || best score : 2.1143685142485014 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 26%|██▌       | 26/100 [09:55<22:33, 18.30s/it]","output_type":"stream"},{"name":"stdout","text":"building 26 || best score : 2.187716231513539 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 27%|██▋       | 27/100 [10:09<20:39, 16.98s/it]","output_type":"stream"},{"name":"stdout","text":"building 27 || best score : 1.279496305728572 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 28%|██▊       | 28/100 [10:29<21:28, 17.89s/it]","output_type":"stream"},{"name":"stdout","text":"building 28 || best score : 4.0475526885961015 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 29%|██▉       | 29/100 [10:49<21:45, 18.38s/it]","output_type":"stream"},{"name":"stdout","text":"building 29 || best score : 3.6494177686008737 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 30%|███       | 30/100 [11:19<25:32, 21.89s/it]","output_type":"stream"},{"name":"stdout","text":"building 30 || best score : 7.1535656118386814 || alpha : 5\n","output_type":"stream"},{"name":"stderr","text":" 31%|███       | 31/100 [11:41<25:16, 21.97s/it]","output_type":"stream"},{"name":"stdout","text":"building 31 || best score : 4.2736800301162665 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 32%|███▏      | 32/100 [11:54<21:56, 19.36s/it]","output_type":"stream"},{"name":"stdout","text":"building 32 || best score : 0.4234495135903367 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 33%|███▎      | 33/100 [12:09<19:57, 17.87s/it]","output_type":"stream"},{"name":"stdout","text":"building 33 || best score : 0.31718940508563853 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 34%|███▍      | 34/100 [12:23<18:34, 16.89s/it]","output_type":"stream"},{"name":"stdout","text":"building 34 || best score : 0.7143829280743348 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 35%|███▌      | 35/100 [12:41<18:33, 17.14s/it]","output_type":"stream"},{"name":"stdout","text":"building 35 || best score : 0.5055309546006589 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 36%|███▌      | 36/100 [12:55<17:25, 16.34s/it]","output_type":"stream"},{"name":"stdout","text":"building 36 || best score : 0.37850131251392766 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 37%|███▋      | 37/100 [13:17<18:49, 17.93s/it]","output_type":"stream"},{"name":"stdout","text":"building 37 || best score : 3.7527021206748543 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 38%|███▊      | 38/100 [13:48<22:42, 21.98s/it]","output_type":"stream"},{"name":"stdout","text":"building 38 || best score : 3.5030792746610957 || alpha : 1\n","output_type":"stream"},{"name":"stderr","text":" 39%|███▉      | 39/100 [14:20<25:21, 24.95s/it]","output_type":"stream"},{"name":"stdout","text":"building 39 || best score : 3.7404985752779814 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 40/100 [14:45<24:49, 24.83s/it]","output_type":"stream"},{"name":"stdout","text":"building 40 || best score : 8.646105555404532 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 41%|████      | 41/100 [15:04<22:43, 23.11s/it]","output_type":"stream"},{"name":"stdout","text":"building 41 || best score : 3.559335615883421 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 42%|████▏     | 42/100 [15:40<26:02, 26.95s/it]","output_type":"stream"},{"name":"stdout","text":"building 42 || best score : 4.653960556043931 || alpha : 3\n","output_type":"stream"},{"name":"stderr","text":" 43%|████▎     | 43/100 [16:20<29:26, 30.99s/it]","output_type":"stream"},{"name":"stdout","text":"building 43 || best score : 5.116832749821416 || alpha : 3\n","output_type":"stream"},{"name":"stderr","text":" 44%|████▍     | 44/100 [16:48<27:51, 29.84s/it]","output_type":"stream"},{"name":"stdout","text":"building 44 || best score : 3.292495673752131 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 45%|████▌     | 45/100 [17:03<23:21, 25.49s/it]","output_type":"stream"},{"name":"stdout","text":"building 45 || best score : 2.2842829781051344 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 46%|████▌     | 46/100 [17:21<20:53, 23.20s/it]","output_type":"stream"},{"name":"stdout","text":"building 46 || best score : 5.104885817682078 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 47%|████▋     | 47/100 [17:35<18:07, 20.53s/it]","output_type":"stream"},{"name":"stdout","text":"building 47 || best score : 4.285527450557575 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 48%|████▊     | 48/100 [17:54<17:16, 19.92s/it]","output_type":"stream"},{"name":"stdout","text":"building 48 || best score : 1.8556346529064331 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 49%|████▉     | 49/100 [18:09<15:46, 18.56s/it]","output_type":"stream"},{"name":"stdout","text":"building 49 || best score : 1.9810676915816998 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 50%|█████     | 50/100 [18:25<14:57, 17.95s/it]","output_type":"stream"},{"name":"stdout","text":"building 50 || best score : 2.0813397310618273 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 51%|█████     | 51/100 [18:42<14:20, 17.55s/it]","output_type":"stream"},{"name":"stdout","text":"building 51 || best score : 3.8714106362573046 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 52%|█████▏    | 52/100 [19:01<14:20, 17.92s/it]","output_type":"stream"},{"name":"stdout","text":"building 52 || best score : 3.272810066405589 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 53%|█████▎    | 53/100 [19:21<14:31, 18.55s/it]","output_type":"stream"},{"name":"stdout","text":"building 53 || best score : 13.448757989978214 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 54%|█████▍    | 54/100 [19:55<17:44, 23.14s/it]","output_type":"stream"},{"name":"stdout","text":"building 54 || best score : 14.802879855667117 || alpha : 3\n","output_type":"stream"},{"name":"stderr","text":" 55%|█████▌    | 55/100 [20:16<16:59, 22.66s/it]","output_type":"stream"},{"name":"stdout","text":"building 55 || best score : 1.5165204752269 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 56%|█████▌    | 56/100 [20:31<14:58, 20.43s/it]","output_type":"stream"},{"name":"stdout","text":"building 56 || best score : 0.6214672452072927 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 57%|█████▋    | 57/100 [20:57<15:47, 22.03s/it]","output_type":"stream"},{"name":"stdout","text":"building 57 || best score : 4.194817310085631 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 58%|█████▊    | 58/100 [21:11<13:44, 19.63s/it]","output_type":"stream"},{"name":"stdout","text":"building 58 || best score : 0.3820424858062876 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 59%|█████▉    | 59/100 [21:43<15:51, 23.20s/it]","output_type":"stream"},{"name":"stdout","text":"building 59 || best score : 4.3241988525156 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 60/100 [22:00<14:17, 21.43s/it]","output_type":"stream"},{"name":"stdout","text":"building 60 || best score : 5.366043505469759 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 61%|██████    | 61/100 [22:16<12:50, 19.77s/it]","output_type":"stream"},{"name":"stdout","text":"building 61 || best score : 3.716245378974095 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 62%|██████▏   | 62/100 [22:41<13:31, 21.36s/it]","output_type":"stream"},{"name":"stdout","text":"building 62 || best score : 4.354566021184845 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 63%|██████▎   | 63/100 [23:26<17:27, 28.31s/it]","output_type":"stream"},{"name":"stdout","text":"building 63 || best score : 4.563158245469306 || alpha : 1\n","output_type":"stream"},{"name":"stderr","text":" 64%|██████▍   | 64/100 [23:48<15:52, 26.47s/it]","output_type":"stream"},{"name":"stdout","text":"building 64 || best score : 3.5797106011186055 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 65%|██████▌   | 65/100 [24:46<20:56, 35.89s/it]","output_type":"stream"},{"name":"stdout","text":"building 65 || best score : 7.963406455428768 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 66%|██████▌   | 66/100 [25:43<24:00, 42.36s/it]","output_type":"stream"},{"name":"stdout","text":"building 66 || best score : 3.254839589080706 || alpha : 3\n","output_type":"stream"},{"name":"stderr","text":" 67%|██████▋   | 67/100 [26:03<19:31, 35.51s/it]","output_type":"stream"},{"name":"stdout","text":"building 67 || best score : 4.748448317779982 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 68%|██████▊   | 68/100 [26:21<16:12, 30.40s/it]","output_type":"stream"},{"name":"stdout","text":"building 68 || best score : 3.003958745755969 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 69%|██████▉   | 69/100 [26:36<13:15, 25.67s/it]","output_type":"stream"},{"name":"stdout","text":"building 69 || best score : 2.5529344591558445 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 70%|███████   | 70/100 [26:52<11:22, 22.74s/it]","output_type":"stream"},{"name":"stdout","text":"building 70 || best score : 2.33185286669241 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 71%|███████   | 71/100 [27:09<10:12, 21.11s/it]","output_type":"stream"},{"name":"stdout","text":"building 71 || best score : 3.7818429247576226 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 72%|███████▏  | 72/100 [27:29<09:39, 20.71s/it]","output_type":"stream"},{"name":"stdout","text":"building 72 || best score : 5.301845112285776 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 73%|███████▎  | 73/100 [27:44<08:35, 19.08s/it]","output_type":"stream"},{"name":"stdout","text":"building 73 || best score : 2.8384983186932446 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 74%|███████▍  | 74/100 [27:59<07:45, 17.89s/it]","output_type":"stream"},{"name":"stdout","text":"building 74 || best score : 5.037367162923875 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 75%|███████▌  | 75/100 [28:19<07:45, 18.63s/it]","output_type":"stream"},{"name":"stdout","text":"building 75 || best score : 5.074210832964962 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 76%|███████▌  | 76/100 [28:40<07:40, 19.20s/it]","output_type":"stream"},{"name":"stdout","text":"building 76 || best score : 4.847741672613207 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 77%|███████▋  | 77/100 [29:01<07:36, 19.84s/it]","output_type":"stream"},{"name":"stdout","text":"building 77 || best score : 2.414383486154715 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 78%|███████▊  | 78/100 [29:24<07:32, 20.59s/it]","output_type":"stream"},{"name":"stdout","text":"building 78 || best score : 3.4331495907975724 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 79%|███████▉  | 79/100 [29:40<06:43, 19.23s/it]","output_type":"stream"},{"name":"stdout","text":"building 79 || best score : 3.2700215880247927 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 80/100 [30:00<06:30, 19.51s/it]","output_type":"stream"},{"name":"stdout","text":"building 80 || best score : 3.3788182398953377 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 81%|████████  | 81/100 [30:31<07:18, 23.10s/it]","output_type":"stream"},{"name":"stdout","text":"building 81 || best score : 2.987949132211474 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 82%|████████▏ | 82/100 [30:50<06:33, 21.84s/it]","output_type":"stream"},{"name":"stdout","text":"building 82 || best score : 4.294488529168283 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 83%|████████▎ | 83/100 [31:17<06:35, 23.26s/it]","output_type":"stream"},{"name":"stdout","text":"building 83 || best score : 3.0040384075451803 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 84%|████████▍ | 84/100 [31:39<06:08, 23.04s/it]","output_type":"stream"},{"name":"stdout","text":"building 84 || best score : 2.781029349320103 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 85%|████████▌ | 85/100 [31:57<05:20, 21.38s/it]","output_type":"stream"},{"name":"stdout","text":"building 85 || best score : 3.128115643355869 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 86%|████████▌ | 86/100 [32:25<05:26, 23.34s/it]","output_type":"stream"},{"name":"stdout","text":"building 86 || best score : 4.092918087935603 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 87%|████████▋ | 87/100 [32:47<05:00, 23.08s/it]","output_type":"stream"},{"name":"stdout","text":"building 87 || best score : 7.62388435605372 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 88%|████████▊ | 88/100 [33:17<05:02, 25.19s/it]","output_type":"stream"},{"name":"stdout","text":"building 88 || best score : 3.0284221359748944 || alpha : 1\n","output_type":"stream"},{"name":"stderr","text":" 89%|████████▉ | 89/100 [33:45<04:45, 25.94s/it]","output_type":"stream"},{"name":"stdout","text":"building 89 || best score : 3.2617501686467336 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 90%|█████████ | 90/100 [34:16<04:34, 27.45s/it]","output_type":"stream"},{"name":"stdout","text":"building 90 || best score : 4.013366115651672 || alpha : 7\n","output_type":"stream"},{"name":"stderr","text":" 91%|█████████ | 91/100 [34:58<04:45, 31.77s/it]","output_type":"stream"},{"name":"stdout","text":"building 91 || best score : 10.834639253609286 || alpha : 1\n","output_type":"stream"},{"name":"stderr","text":" 92%|█████████▏| 92/100 [35:37<04:32, 34.08s/it]","output_type":"stream"},{"name":"stdout","text":"building 92 || best score : 3.440087476061091 || alpha : 1\n","output_type":"stream"},{"name":"stderr","text":" 93%|█████████▎| 93/100 [36:04<03:42, 31.75s/it]","output_type":"stream"},{"name":"stdout","text":"building 93 || best score : 6.2066751753431575 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 94%|█████████▍| 94/100 [36:21<02:44, 27.47s/it]","output_type":"stream"},{"name":"stdout","text":"building 94 || best score : 6.108287951252434 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 95%|█████████▌| 95/100 [36:44<02:09, 25.99s/it]","output_type":"stream"},{"name":"stdout","text":"building 95 || best score : 13.317026198043353 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 96%|█████████▌| 96/100 [36:59<01:31, 22.81s/it]","output_type":"stream"},{"name":"stdout","text":"building 96 || best score : 2.816158743531264 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 97%|█████████▋| 97/100 [37:26<01:11, 23.90s/it]","output_type":"stream"},{"name":"stdout","text":"building 97 || best score : 4.998493637714644 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 98%|█████████▊| 98/100 [37:56<00:52, 26.02s/it]","output_type":"stream"},{"name":"stdout","text":"building 98 || best score : 12.345406990706872 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":" 99%|█████████▉| 99/100 [38:22<00:25, 25.80s/it]","output_type":"stream"},{"name":"stdout","text":"building 99 || best score : 2.940478020710276 || alpha : 0\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 100/100 [38:57<00:00, 23.37s/it]","output_type":"stream"},{"name":"stdout","text":"building 100 || best score : 4.851064779177453 || alpha : 50\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"   alpha  best_it\n0      0      364\n1      0      307\n2    100      216\n3      0      300\n4      0      448","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>alpha</th>\n      <th>best_it</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>364</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>307</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>100</td>\n      <td>216</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>300</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>448</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"no_df = pd.DataFrame({'score':scores})\nplt.bar(np.arange(len(no_df))+1, no_df['score'])\nplt.plot([1,100], [10, 10], color = 'red')","metadata":{"execution":{"iopub.status.busy":"2023-07-29T17:01:40.949691Z","iopub.execute_input":"2023-07-29T17:01:40.950674Z","iopub.status.idle":"2023-07-29T17:01:41.443519Z","shell.execute_reply.started":"2023-07-29T17:01:40.950633Z","shell.execute_reply":"2023-07-29T17:01:41.442448Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"[<matplotlib.lines.Line2D at 0x79795cfa0610>]"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"preds = np.array([]) \nfor i in tqdm(range(100)):\n    \n    pred_df = pd.DataFrame()   # 시드별 예측값을 담을 data frame\n    \n    for seed in [0,1,2,3,4]: # 각 시드별 예측\n        y_train = train.loc[train.building == i+1, 'target']\n        x_train, x_test = train.loc[train.building == i+1, ].iloc[:, 3:].drop(['target'], axis=1), test.loc[test.building == i+1, ].iloc[:,3:]\n        x_test = x_test[x_train.columns]\n        \n        \n        xgb = XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n                 colsample_bynode=1, colsample_bytree=0.8, eta=0.01, gamma=0,\n                 gpu_id=-1, importance_type='gain', interaction_constraints='',\n                 learning_rate=0.00999999978, max_delta_step=0, max_depth=5,\n                 min_child_weight=6, monotone_constraints='()',\n                 n_estimators=best_it[i], n_jobs=0, num_parallel_tree=1,\n                 random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n                 seed=seed, subsample=0.9, tree_method='exact', validate_parameters=1,\n                 verbosity=None)\n        \n        if xgb_params.loc[i, 'alpha'] != 0:\n            xgb.set_params(**{'objective':weighted_mse(xgb_params.loc[i, 'alpha'])})\n        \n        xgb.fit(x_train, y_train)\n        y_pred = xgb.predict(x_test)\n        pred_df.loc[:,seed] = y_pred   # 각 시드별 예측 담기\n        \n    pred = pred_df.mean(axis=1)        # (i+1)번째 건물의 예측 =  (i+1)번째 건물의 각 시드별 예측 평균값\n    preds = np.append(preds, pred)   \n    \nsubmission = pd.read_csv('/kaggle/input/big-one/sample_submission.csv')\nsubmission['answer'] = preds\nsubmission.to_csv('./submission_xgb.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2023-07-29T17:01:41.444699Z","iopub.execute_input":"2023-07-29T17:01:41.445008Z","iopub.status.idle":"2023-07-29T17:11:16.043111Z","shell.execute_reply.started":"2023-07-29T17:01:41.444980Z","shell.execute_reply":"2023-07-29T17:11:16.041716Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"100%|██████████| 100/100 [09:34<00:00,  5.74s/it]\n","output_type":"stream"}]},{"cell_type":"code","source":"submission","metadata":{"execution":{"iopub.status.busy":"2023-07-29T17:13:58.077207Z","iopub.execute_input":"2023-07-29T17:13:58.077608Z","iopub.status.idle":"2023-07-29T17:13:58.093378Z","shell.execute_reply.started":"2023-07-29T17:13:58.077576Z","shell.execute_reply":"2023-07-29T17:13:58.092003Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"         num_date_time       answer\n0        1_20220825 00  1963.044922\n1        1_20220825 01  1853.935913\n2        1_20220825 02  1696.383423\n3        1_20220825 03  1631.057495\n4        1_20220825 04  1637.963623\n...                ...          ...\n16795  100_20220831 19   918.836121\n16796  100_20220831 20   873.771301\n16797  100_20220831 21   787.078735\n16798  100_20220831 22   644.956726\n16799  100_20220831 23   544.311829\n\n[16800 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>num_date_time</th>\n      <th>answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1_20220825 00</td>\n      <td>1963.044922</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1_20220825 01</td>\n      <td>1853.935913</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1_20220825 02</td>\n      <td>1696.383423</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1_20220825 03</td>\n      <td>1631.057495</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1_20220825 04</td>\n      <td>1637.963623</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>16795</th>\n      <td>100_20220831 19</td>\n      <td>918.836121</td>\n    </tr>\n    <tr>\n      <th>16796</th>\n      <td>100_20220831 20</td>\n      <td>873.771301</td>\n    </tr>\n    <tr>\n      <th>16797</th>\n      <td>100_20220831 21</td>\n      <td>787.078735</td>\n    </tr>\n    <tr>\n      <th>16798</th>\n      <td>100_20220831 22</td>\n      <td>644.956726</td>\n    </tr>\n    <tr>\n      <th>16799</th>\n      <td>100_20220831 23</td>\n      <td>544.311829</td>\n    </tr>\n  </tbody>\n</table>\n<p>16800 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}